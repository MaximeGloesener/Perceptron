{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.utils import shuffle\n",
    "import csv \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lecture des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat(\"data_doc.mat\")\n",
    "X = mat['Xts'].T.toarray()\n",
    "df_y = pd.DataFrame(mat['yts'])\n",
    "y = pd.get_dummies(df_y[0]).to_numpy() # OneHotEncoding\n",
    "X_to_predict = mat['Xvr'].T.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Normalisation entre 0 et 1 \\nX = normalize(X)\\nX_to_predict = normalize(X_to_predict)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Normalisation entre 0 et 1 \n",
    "X = normalize(X)\n",
    "X_to_predict = normalize(X_to_predict)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation autour de 0 moyenne nulle et même variance\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_to_predict = scaler.transform(X_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data en entrainement et validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self, mots, classe, method=None):\n",
    "        \"\"\"Initialisation des poids et des biais \"\"\"\n",
    "        if method is None:\n",
    "            # init uniform\n",
    "            self.weights = np.random.randn(mots, classe)\n",
    "            self.biases = np.random.randn(classe)\n",
    "        elif method == \"xavier\":\n",
    "            F_in = mots\n",
    "            F_out = classe \n",
    "            limit = np.sqrt(6 / float(F_in + F_out))\n",
    "            self.weights = np.random.uniform(low=-limit, high=limit, size=(F_in, F_out))\n",
    "            self.biases = np.random.randn(classe)\n",
    "            \n",
    "       \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass pour calculer la sortie du réseau\"\"\"\n",
    "        # sortie z = W^t*X+B\n",
    "        z = np.dot(self.weights.T, x) + self.biases\n",
    "        # fct d'activation = sigmoïde\n",
    "        activation = sigmoid(z)\n",
    "        return z, activation\n",
    "\n",
    "\n",
    "    def evaluate_gradient(self, x, y):\n",
    "        \"\"\"Calcul des dérivées partielles de la loss pour un itéré x\"\"\"\n",
    "        # on récupère la valeur de z et act(z) \n",
    "        z, activation = self.forward(x)\n",
    "        # calculer les dérivées partielles pour la couche de sortie par rapport à W et B\n",
    "        delta_b = (activation-y)*sigmoid_prime(z)\n",
    "        delta_w = np.outer(x, delta_b)\n",
    "        return delta_b, delta_w\n",
    "\n",
    "\n",
    "    \n",
    "    def compute_gradient(self, X, y, lr):\n",
    "        \"\"\"Calcul le gradient pour un batch\"\"\"\n",
    "        \n",
    "        # stocker la somme des gradients des x du batch\n",
    "        somme_delta_b = np.zeros(self.biases.shape)\n",
    "        somme_delta_w = np.zeros(self.weights.shape)\n",
    "\n",
    "        for x,y in zip(X,y):\n",
    "            delta_b, delta_w = self.evaluate_gradient(x, y)\n",
    "            somme_delta_b+=delta_b\n",
    "            somme_delta_w+=delta_w\n",
    "        \n",
    "        return somme_delta_b, somme_delta_w\n",
    "\n",
    "\n",
    "                                                                                                                                  \n",
    "    def SGD(self, X, y, lr, epochs):\n",
    "        \"\"\"SGD batchsize=1\"\"\"\n",
    "        # shuffle les données\n",
    "        X, y = shuffle(X,y)\n",
    "        for epoch in range(epochs):\n",
    "            # à chaque époque on parcourt tous les X, on calcule le gradient et on met à jour les poids et le biais pour chaque X\n",
    "            for i in range(len(X)):\n",
    "                somme_delta_b, somme_delta_w =  self.compute_gradient(X[i], y[i], lr)\n",
    "                # update les poids      \n",
    "                self.weights -= (lr/X[i].shape[0])*somme_delta_w \n",
    "                self.biases -= (lr/X[i].shape[0])*somme_delta_b\n",
    "\n",
    "            # calcul de l'accuracy et de la loss pour cette époque \n",
    "            accuracy, loss = self.evaluate_model(X, y)\n",
    "            print(f'Epoch {epoch}')\n",
    "            print(f'Accuracy = {accuracy}')\n",
    "            print(f'Loss = {loss}')\n",
    "\n",
    "    def GD(self, X, y, lr, epochs):\n",
    "        \"\"\"Gradient descent\"\"\"\n",
    "        X, y = shuffle(X,y)\n",
    "        for epoch in range(epochs):\n",
    "            # à chaque époque, on met le gradient une seule fosi à jour\n",
    "            somme_delta_b, somme_delta_w =  self.compute_gradient(X, y, lr)\n",
    "            # update les poids      \n",
    "            self.weights -= (lr/X.shape[0])*somme_delta_w \n",
    "            self.biases -= (lr/X.shape[0])*somme_delta_b\n",
    "\n",
    "            # calcul de l'accuracy et de la loss pour cette époque \n",
    "            accuracy, loss = self.evaluate_model(X, y)\n",
    "            print(f'Epoch {epoch}')\n",
    "            print(f'Accuracy = {accuracy}')\n",
    "            print(f'Loss = {loss}')\n",
    "\n",
    "    \n",
    "    def SGD_batch(self, X, y, lr, epochs, batch_size):\n",
    "        \"\"\"SGD+mini-batch\"\"\"\n",
    "        # shuffle les données\n",
    "        X, y = shuffle(X,y)\n",
    "        losses = [10**8]\n",
    "        for epoch in range(epochs):\n",
    "            # à chaque époque, on met à jour W et B avec mini-batchs\n",
    "            num_samples = y.shape[0]\n",
    "            ret = num_samples % batch_size\n",
    "            # si taille des données pas divisable par batch size alors resize les données\n",
    "            if ret != 0:\n",
    "                X_resize = X[:len(X)-ret]\n",
    "                y_resize = y[:len(y)-ret]\n",
    "\n",
    "            iterations = int(num_samples / batch_size)\n",
    "            print(f\"Nombre d'itérations par époque = {iterations}\")\n",
    "            for i in range(iterations):\n",
    "                # pour chaque mini-batch on veut entrainer le modèle et mettre à jour les poids\n",
    "                start = i * batch_size\n",
    "                end = start+batch_size\n",
    "                X_batch = X_resize[start:end, :]\n",
    "                y_batch = y_resize[start:end, :]\n",
    "                somme_delta_b, somme_delta_w =  self.compute_gradient(X_batch, y_batch, lr)\n",
    "                # update les poids      \n",
    "                self.weights -= (lr/X_batch.shape[0])*somme_delta_w \n",
    "                self.biases -= (lr/X_batch.shape[0])*somme_delta_b\n",
    "\n",
    "            # calcul de l'accuracy et de la loss pour cette époque \n",
    "            accuracy, loss = self.evaluate_model(X, y)\n",
    "            print(f'Epoch {epoch}')\n",
    "            print(f'Accuracy = {accuracy}')\n",
    "            print(f'Loss = {loss}')\n",
    "\n",
    "            # update le learning rate si on a une meilleure loss alors lr/2\n",
    "            if loss>losses[-1]:\n",
    "                lr/=2\n",
    "            losses.append(loss)\n",
    "\n",
    "    def Adam(self, X, y, lr, epochs, batch_size, X_val, y_val):\n",
    "        # init les paramètres pour Adam\n",
    "        beta_1 = 0.9\n",
    "        beta_2 = 0.999\t\t\t\t\t\n",
    "        epsilon = 1e-8\n",
    "        # init le vecteur\n",
    "        t = 1\t\t\t\t\t\t\n",
    "        m_dw = m_db = v_dw = v_db = 0 \n",
    "        X, y = shuffle(X,y)\n",
    "        losses = [10**8]\n",
    "        val_losses = [10**8]\n",
    "        # flag utilisé pour early stopping si val loss >>>\n",
    "        flag = 0    \n",
    "        for epoch in range(epochs):\n",
    "            # à chaque époque, on met à jour W et B avec mini-batchs\n",
    "            num_samples = y.shape[0]\n",
    "            ret = num_samples % batch_size\n",
    "            # si taille des données pas divisable par batch size alors resize les données\n",
    "            if ret != 0:\n",
    "                X_resize = X[:len(X)-ret]\n",
    "                y_resize = y[:len(y)-ret]\n",
    "\n",
    "            iterations = int(num_samples / batch_size)\n",
    "            print(f\"Nombre d'itérations par époque = {iterations}\")\n",
    "            for i in range(iterations):\n",
    "                # pour chaque mini-batch on veut entrainer le modèle et mettre à jour les poids\n",
    "                start = i * batch_size\n",
    "                end = start+batch_size\n",
    "                X_batch = X_resize[start:end, :]\n",
    "                y_batch = y_resize[start:end, :]\n",
    "                grad_b, grad_w =  self.compute_gradient(X_batch, y_batch, lr)\n",
    "                # adam update\n",
    "                # momentum poids\n",
    "                m_dw = beta_1*m_dw + (1-beta_1)*grad_w\n",
    "                # momentum biais\n",
    "                m_db = beta_1*m_db + (1-beta_1)*grad_b\n",
    "\n",
    "                # poids\n",
    "                v_dw = beta_2*v_dw + (1-beta_2)*(grad_w**2)\n",
    "                # biais\n",
    "                v_db = beta_2*v_db + (1-beta_2)*(grad_b**2)\n",
    "\n",
    "                # correction\n",
    "                m_dw_corr = m_dw/(1-beta_1**t)\n",
    "                m_db_corr = m_db/(1-beta_1**t)\n",
    "                v_dw_corr = v_dw/(1-beta_2**t)\n",
    "                v_db_corr = v_db/(1-beta_2**t)\n",
    "                # update les poids      \n",
    "                self.weights -= (lr/X.shape[0])*(m_dw_corr/(np.sqrt(v_dw_corr)+epsilon))\n",
    "                self.biases -= (lr/X.shape[0])*(m_db_corr/(np.sqrt(v_db_corr)+epsilon))\n",
    "\n",
    "            # calcul de l'accuracy et de la loss pour cette époque \n",
    "            accuracy, loss = self.evaluate_model(X, y)\n",
    "            print(f'Epoch {epoch}')\n",
    "            print(f'Accuracy = {accuracy}')\n",
    "            print(f'Loss = {loss}')\n",
    "            if loss > losses[-1]:\n",
    "                lr /= 2\n",
    "            losses.append(loss)\n",
    "\n",
    "            val_accuracy, val_loss = self.evaluate_model(X_val, y_val)\n",
    "            print(f'Val accuracy = {val_accuracy}')\n",
    "            print(f'Val loss = {val_loss}')\n",
    "            if val_loss > val_losses[-1]:\n",
    "                flag+=1\n",
    "            else:\n",
    "                flag=0\n",
    "            if flag>5:\n",
    "                print('EARLY STOPPING')\n",
    "                exit()\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Prediction sur des nouvelles données\"\"\"\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            z, act = self.forward(x)\n",
    "            preds.append(act)\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def evaluate_model(self, X, Y):\n",
    "        \"\"\"Calcule l'accuracy du modèle\n",
    "        X = vecteur qui contient des X d'entrées\n",
    "        Y = vecteur de vraie valeurs\n",
    "        \"\"\"\n",
    "        preds = self.predict(X)\n",
    "        loss = (1/(2*Y.shape[0])) * np.linalg.norm(preds - Y, 'fro') ** 2\n",
    "        predicted = np.array([pred.argmax() for pred in preds])\n",
    "        true_y = np.array([y.argmax() for y in Y])\n",
    "        # si predicted == la vraie valeur (test_y) alors True sinon False \n",
    "        correct = predicted == true_y\n",
    "        accuracy = (correct.sum() / len(correct))\n",
    "        return accuracy, loss\n",
    "\n",
    "    def write_output(self, X):\n",
    "        preds = self.predict(X)\n",
    "        predicted = np.array([np.argmax(pred) for pred in preds])\n",
    "        with open('output.csv' ,'w', newline='') as fout:\n",
    "            writer = csv.writer(fout)\n",
    "            writer.writerow([\"id\", \"class\"])\n",
    "            for i,pred in enumerate(predicted, start=1):\n",
    "                writer.writerow([i, (pred+1)*100+1])\n",
    "\n",
    "        \n",
    "def sigmoid(z):\n",
    "    \"\"\"Fonction d'activation sigmoïde\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Dérivée de la sigmoïde\"\"\"\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(X.shape[1], y.shape[1], 'xavier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'itérations par époque = 196\n",
      "Epoch 0\n",
      "Accuracy = 0.06478828398599172\n",
      "Loss = 2.5424691081387976\n",
      "Val accuracy = 0.0651862464183381\n",
      "Val loss = 2.683601492496913\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 1\n",
      "Accuracy = 0.07529449219993632\n",
      "Loss = 2.4203712320972586\n",
      "Val accuracy = 0.07521489971346705\n",
      "Val loss = 2.648695928303727\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 2\n",
      "Accuracy = 0.08373129576567973\n",
      "Loss = 2.326065447864545\n",
      "Val accuracy = 0.08237822349570201\n",
      "Val loss = 2.621720065909946\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 3\n",
      "Accuracy = 0.09137217446673034\n",
      "Loss = 2.245741361750682\n",
      "Val accuracy = 0.09097421203438395\n",
      "Val loss = 2.598579070389861\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 4\n",
      "Accuracy = 0.09893346068131169\n",
      "Loss = 2.1742163150113702\n",
      "Val accuracy = 0.09742120343839542\n",
      "Val loss = 2.578026168204555\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 5\n",
      "Accuracy = 0.10776822667940146\n",
      "Loss = 2.1088944687796705\n",
      "Val accuracy = 0.1010028653295129\n",
      "Val loss = 2.559375938006892\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 6\n",
      "Accuracy = 0.1157274753263292\n",
      "Loss = 2.04829064574295\n",
      "Val accuracy = 0.10888252148997135\n",
      "Val loss = 2.5422675963188115\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 7\n",
      "Accuracy = 0.12432346386501114\n",
      "Loss = 1.9914719898679423\n",
      "Val accuracy = 0.11031518624641834\n",
      "Val loss = 2.526486089260464\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 8\n",
      "Accuracy = 0.13514804202483285\n",
      "Loss = 1.937800785240278\n",
      "Val accuracy = 0.12106017191977077\n",
      "Val loss = 2.5118669647722807\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 9\n",
      "Accuracy = 0.1441419929958612\n",
      "Loss = 1.8868272294469643\n",
      "Val accuracy = 0.12607449856733524\n",
      "Val loss = 2.498275762411994\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 10\n",
      "Accuracy = 0.15353390639923592\n",
      "Loss = 1.838217821743691\n",
      "Val accuracy = 0.1361031518624642\n",
      "Val loss = 2.4855939526409685\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 11\n",
      "Accuracy = 0.1637217446673034\n",
      "Loss = 1.7917027620058803\n",
      "Val accuracy = 0.14255014326647564\n",
      "Val loss = 2.4737237026403545\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 12\n",
      "Accuracy = 0.17335243553008595\n",
      "Loss = 1.747065992873892\n",
      "Val accuracy = 0.1504297994269341\n",
      "Val loss = 2.462594085934922\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 13\n",
      "Accuracy = 0.18425660617637696\n",
      "Loss = 1.7041347695535847\n",
      "Val accuracy = 0.15616045845272206\n",
      "Val loss = 2.45215046550915\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 14\n",
      "Accuracy = 0.19229544730977396\n",
      "Loss = 1.6627670330779745\n",
      "Val accuracy = 0.1654727793696275\n",
      "Val loss = 2.442342013613938\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 15\n",
      "Accuracy = 0.2034383954154728\n",
      "Loss = 1.6228437304411278\n",
      "Val accuracy = 0.17263610315186245\n",
      "Val loss = 2.4331197100862996\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 16\n",
      "Accuracy = 0.21513849092645654\n",
      "Loss = 1.584264178837627\n",
      "Val accuracy = 0.17765042979942694\n",
      "Val loss = 2.4244372511327557\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 17\n",
      "Accuracy = 0.22532632919452403\n",
      "Loss = 1.5469434039084264\n",
      "Val accuracy = 0.19054441260744986\n",
      "Val loss = 2.416251790072602\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 18\n",
      "Accuracy = 0.23646927730022285\n",
      "Loss = 1.510809676064528\n",
      "Val accuracy = 0.19555873925501432\n",
      "Val loss = 2.4085241420497168\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 19\n",
      "Accuracy = 0.24673670805475964\n",
      "Loss = 1.4758007518980214\n",
      "Val accuracy = 0.19627507163323782\n",
      "Val loss = 2.4012186212645577\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 20\n",
      "Accuracy = 0.2567653613498886\n",
      "Loss = 1.441860697471943\n",
      "Val accuracy = 0.21060171919770773\n",
      "Val loss = 2.39430268982342\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 21\n",
      "Accuracy = 0.26854504934734164\n",
      "Loss = 1.408938874162525\n",
      "Val accuracy = 0.2184813753581662\n",
      "Val loss = 2.3877465299997622\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 22\n",
      "Accuracy = 0.27929003502069405\n",
      "Loss = 1.3769899511359438\n",
      "Val accuracy = 0.22707736389684813\n",
      "Val loss = 2.3815226724046332\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 23\n",
      "Accuracy = 0.2921044253422477\n",
      "Loss = 1.345973873337628\n",
      "Val accuracy = 0.23638968481375358\n",
      "Val loss = 2.375605769401794\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 24\n",
      "Accuracy = 0.30308818847500796\n",
      "Loss = 1.315855373705736\n",
      "Val accuracy = 0.24641833810888253\n",
      "Val loss = 2.3699725349653\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 25\n",
      "Accuracy = 0.31502706144539955\n",
      "Loss = 1.2866030893217846\n",
      "Val accuracy = 0.25358166189111747\n",
      "Val loss = 2.364601788284537\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 26\n",
      "Accuracy = 0.3253740846864056\n",
      "Loss = 1.2581885954115952\n",
      "Val accuracy = 0.2614613180515759\n",
      "Val loss = 2.3594744385738724\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 27\n",
      "Accuracy = 0.336676217765043\n",
      "Loss = 1.2305855899983942\n",
      "Val accuracy = 0.2700573065902579\n",
      "Val loss = 2.35457330727384\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 28\n",
      "Accuracy = 0.3471824259789876\n",
      "Loss = 1.2037692174624859\n",
      "Val accuracy = 0.27578796561604585\n",
      "Val loss = 2.3498829247405935\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 29\n",
      "Accuracy = 0.3576090417064629\n",
      "Loss = 1.1777157252147223\n",
      "Val accuracy = 0.2808022922636103\n",
      "Val loss = 2.345389493050835\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 30\n",
      "Accuracy = 0.36907035975803887\n",
      "Loss = 1.1524028466962744\n",
      "Val accuracy = 0.28796561604584525\n",
      "Val loss = 2.3410809547067895\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 31\n",
      "Accuracy = 0.3804520853231455\n",
      "Loss = 1.1278103075469954\n",
      "Val accuracy = 0.2979942693409742\n",
      "Val loss = 2.336946910126872\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 32\n",
      "Accuracy = 0.3931072906717606\n",
      "Loss = 1.103919015587254\n",
      "Val accuracy = 0.30515759312320917\n",
      "Val loss = 2.332978180187406\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 33\n",
      "Accuracy = 0.40369309137217446\n",
      "Loss = 1.080709904212268\n",
      "Val accuracy = 0.3116045845272206\n",
      "Val loss = 2.3291662155734825\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 34\n",
      "Accuracy = 0.4151544094237504\n",
      "Loss = 1.058164291776945\n",
      "Val accuracy = 0.31805157593123207\n",
      "Val loss = 2.325502846253142\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 35\n",
      "Accuracy = 0.4263769500159185\n",
      "Loss = 1.0362647369449716\n",
      "Val accuracy = 0.32736389684813755\n",
      "Val loss = 2.321980346604526\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 36\n",
      "Accuracy = 0.43592804839223176\n",
      "Loss = 1.0149954393949123\n",
      "Val accuracy = 0.332378223495702\n",
      "Val loss = 2.318591466050639\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 37\n",
      "Accuracy = 0.4456383317414836\n",
      "Loss = 0.9943420797981781\n",
      "Val accuracy = 0.33739255014326647\n",
      "Val loss = 2.315329463715158\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 38\n",
      "Accuracy = 0.45534861509073543\n",
      "Loss = 0.9742910035768367\n",
      "Val accuracy = 0.3424068767908309\n",
      "Val loss = 2.312188311399143\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 39\n",
      "Accuracy = 0.4654568608723337\n",
      "Loss = 0.9548283649703746\n",
      "Val accuracy = 0.34742120343839544\n",
      "Val loss = 2.309162832052578\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 40\n",
      "Accuracy = 0.4750875517351162\n",
      "Loss = 0.9359399862810307\n",
      "Val accuracy = 0.35744985673352436\n",
      "Val loss = 2.306248509969073\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 41\n",
      "Accuracy = 0.4855937599490608\n",
      "Loss = 0.9176117642381606\n",
      "Val accuracy = 0.3653295128939828\n",
      "Val loss = 2.303441193206609\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 42\n",
      "Accuracy = 0.4946673034065584\n",
      "Loss = 0.8998300141174631\n",
      "Val accuracy = 0.36962750716332377\n",
      "Val loss = 2.300736928777299\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 43\n",
      "Accuracy = 0.502865329512894\n",
      "Loss = 0.8825815550620597\n",
      "Val accuracy = 0.37822349570200575\n",
      "Val loss = 2.2981319184754536\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 44\n",
      "Accuracy = 0.5114613180515759\n",
      "Loss = 0.8658536912561674\n",
      "Val accuracy = 0.3818051575931232\n",
      "Val loss = 2.2956225226443805\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 45\n",
      "Accuracy = 0.5191817892390959\n",
      "Loss = 0.8496341849381984\n",
      "Val accuracy = 0.3875358166189112\n",
      "Val loss = 2.2932052715227402\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 46\n",
      "Accuracy = 0.5280961477236549\n",
      "Loss = 0.833911181737164\n",
      "Val accuracy = 0.39183381088825214\n",
      "Val loss = 2.290876869276567\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 47\n",
      "Accuracy = 0.5362941738299905\n",
      "Loss = 0.8186730696071046\n",
      "Val accuracy = 0.40114613180515757\n",
      "Val loss = 2.2886341896932834\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 48\n",
      "Accuracy = 0.5454473097739574\n",
      "Loss = 0.8039083633591905\n",
      "Val accuracy = 0.4068767908309456\n",
      "Val loss = 2.2864742702115777\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 49\n",
      "Accuracy = 0.5532473734479465\n",
      "Loss = 0.7896056584943701\n",
      "Val accuracy = 0.41189111747851004\n",
      "Val loss = 2.2843943097629515\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 50\n",
      "Accuracy = 0.5619229544730977\n",
      "Loss = 0.7757535823778631\n",
      "Val accuracy = 0.4169054441260745\n",
      "Val loss = 2.2823916691508637\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 51\n",
      "Accuracy = 0.5690862782553326\n",
      "Loss = 0.7623407505801494\n",
      "Val accuracy = 0.42048710601719197\n",
      "Val loss = 2.2804638665329926\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 52\n",
      "Accuracy = 0.5759312320916905\n",
      "Loss = 0.7493558391448868\n",
      "Val accuracy = 0.4262177650429799\n",
      "Val loss = 2.278608557440301\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 53\n",
      "Accuracy = 0.5831741483603948\n",
      "Loss = 0.7367877561215128\n",
      "Val accuracy = 0.4297994269340974\n",
      "Val loss = 2.2768234935939984\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 54\n",
      "Accuracy = 0.5908946195479147\n",
      "Loss = 0.7246256900854793\n",
      "Val accuracy = 0.4362464183381089\n",
      "Val loss = 2.275106470727126\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 55\n",
      "Accuracy = 0.5981375358166189\n",
      "Loss = 0.7128588894268995\n",
      "Val accuracy = 0.43982808022922637\n",
      "Val loss = 2.2734552917849093\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 56\n",
      "Accuracy = 0.6066539318688315\n",
      "Loss = 0.7014764023544711\n",
      "Val accuracy = 0.4477077363896848\n",
      "Val loss = 2.2718677607028654\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 57\n",
      "Accuracy = 0.6146927730022286\n",
      "Loss = 0.6904670666690974\n",
      "Val accuracy = 0.4498567335243553\n",
      "Val loss = 2.270341688809019\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 58\n",
      "Accuracy = 0.6220948742438713\n",
      "Loss = 0.6798196595307129\n",
      "Val accuracy = 0.4584527220630373\n",
      "Val loss = 2.2688748958039313\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 59\n",
      "Accuracy = 0.6282234957020058\n",
      "Loss = 0.6695230067954447\n",
      "Val accuracy = 0.4699140401146132\n",
      "Val loss = 2.2674652119224548\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 60\n",
      "Accuracy = 0.6353868194842407\n",
      "Loss = 0.659566022236028\n",
      "Val accuracy = 0.47421203438395415\n",
      "Val loss = 2.266110491855317\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 61\n",
      "Accuracy = 0.6405603311047438\n",
      "Loss = 0.649937714127712\n",
      "Val accuracy = 0.4792263610315186\n",
      "Val loss = 2.264808643538987\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 62\n",
      "Accuracy = 0.6474848774275709\n",
      "Loss = 0.6406271840842969\n",
      "Val accuracy = 0.48495702005730656\n",
      "Val loss = 2.2635576686071768\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 63\n",
      "Accuracy = 0.6533747214262974\n",
      "Loss = 0.6316236680633025\n",
      "Val accuracy = 0.4906876790830946\n",
      "Val loss = 2.2623557006311272\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 64\n",
      "Accuracy = 0.6580706781279847\n",
      "Loss = 0.6229166741171553\n",
      "Val accuracy = 0.49426934097421205\n",
      "Val loss = 2.2612010198875256\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 65\n",
      "Accuracy = 0.6626870423432027\n",
      "Loss = 0.6144961710347893\n",
      "Val accuracy = 0.49641833810888253\n",
      "Val loss = 2.2600920368763697\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 66\n",
      "Accuracy = 0.6666666666666666\n",
      "Loss = 0.6063526786149892\n",
      "Val accuracy = 0.5007163323782235\n",
      "Val loss = 2.259027261922246\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 67\n",
      "Accuracy = 0.6715218083412926\n",
      "Loss = 0.5984771599088634\n",
      "Val accuracy = 0.502865329512894\n",
      "Val loss = 2.2580052842268645\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 68\n",
      "Accuracy = 0.6772524673670806\n",
      "Loss = 0.5908607893649142\n",
      "Val accuracy = 0.5085959885386819\n",
      "Val loss = 2.2570247653889157\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 69\n",
      "Accuracy = 0.6833014963387456\n",
      "Loss = 0.5834947832636416\n",
      "Val accuracy = 0.5136103151862464\n",
      "Val loss = 2.2560844321774307\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 70\n",
      "Accuracy = 0.6887933779051257\n",
      "Loss = 0.576370402126259\n",
      "Val accuracy = 0.5186246418338109\n",
      "Val loss = 2.2551830532300756\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 71\n",
      "Accuracy = 0.694603629417383\n",
      "Loss = 0.5694790635914736\n",
      "Val accuracy = 0.5207736389684814\n",
      "Val loss = 2.254319404987891\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 72\n",
      "Accuracy = 0.6999363260108246\n",
      "Loss = 0.5628124320856639\n",
      "Val accuracy = 0.5229226361031518\n",
      "Val loss = 2.2534922467003446\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 73\n",
      "Accuracy = 0.7031200254695956\n",
      "Loss = 0.5563624162800755\n",
      "Val accuracy = 0.5257879656160458\n",
      "Val loss = 2.2527003162324566\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 74\n",
      "Accuracy = 0.7073384272524673\n",
      "Loss = 0.5501211007645928\n",
      "Val accuracy = 0.5279369627507163\n",
      "Val loss = 2.2519423435749437\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 75\n",
      "Accuracy = 0.711556829035339\n",
      "Loss = 0.5440806806596279\n",
      "Val accuracy = 0.5329512893982808\n",
      "Val loss = 2.251217072425984\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 76\n",
      "Accuracy = 0.7159344157911494\n",
      "Loss = 0.5382334517571075\n",
      "Val accuracy = 0.5379656160458453\n",
      "Val loss = 2.2505232809760147\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 77\n",
      "Accuracy = 0.7200732250875518\n",
      "Loss = 0.532571871871422\n",
      "Val accuracy = 0.5429799426934098\n",
      "Val loss = 2.2498597969248175\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 78\n",
      "Accuracy = 0.7242916268704235\n",
      "Loss = 0.5270886801674097\n",
      "Val accuracy = 0.5472779369627507\n",
      "Val loss = 2.2492255065992137\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 79\n",
      "Accuracy = 0.7277141037886024\n",
      "Loss = 0.5217770411675402\n",
      "Val accuracy = 0.5515759312320917\n",
      "Val loss = 2.248619361407031\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 80\n",
      "Accuracy = 0.7308182107609041\n",
      "Loss = 0.516630666348809\n",
      "Val accuracy = 0.5530085959885387\n",
      "Val loss = 2.248040384568444\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 81\n",
      "Accuracy = 0.7346386501114295\n",
      "Loss = 0.511643864928269\n",
      "Val accuracy = 0.5544412607449857\n",
      "Val loss = 2.247487677560119\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 82\n",
      "Accuracy = 0.7374243871378542\n",
      "Loss = 0.5068114821221764\n",
      "Val accuracy = 0.5565902578796562\n",
      "Val loss = 2.2469604217723966\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 83\n",
      "Accuracy = 0.7406080865966252\n",
      "Loss = 0.5021287076988905\n",
      "Val accuracy = 0.5601719197707736\n",
      "Val loss = 2.2464578701664557\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 84\n",
      "Accuracy = 0.7440305635148042\n",
      "Loss = 0.4975908163627167\n",
      "Val accuracy = 0.5623209169054442\n",
      "Val loss = 2.245979329261302\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 85\n",
      "Accuracy = 0.7464183381088825\n",
      "Loss = 0.49319296998525936\n",
      "Val accuracy = 0.5644699140401146\n",
      "Val loss = 2.245524139729954\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 86\n",
      "Accuracy = 0.7490448901623686\n",
      "Loss = 0.48893015270681994\n",
      "Val accuracy = 0.5680515759312321\n",
      "Val loss = 2.2450916654282604\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 87\n",
      "Accuracy = 0.7506367398917542\n",
      "Loss = 0.48479720272255106\n",
      "Val accuracy = 0.5694842406876791\n",
      "Val loss = 2.2446812957147477\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 88\n",
      "Accuracy = 0.7527857370264247\n",
      "Loss = 0.48078888332481096\n",
      "Val accuracy = 0.5694842406876791\n",
      "Val loss = 2.244292460878522\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 89\n",
      "Accuracy = 0.7554122890799109\n",
      "Loss = 0.47689996646489435\n",
      "Val accuracy = 0.5709169054441261\n",
      "Val loss = 2.24392465671868\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 90\n",
      "Accuracy = 0.7578796561604585\n",
      "Loss = 0.47312531938714913\n",
      "Val accuracy = 0.576647564469914\n",
      "Val loss = 2.243577469824041\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 91\n",
      "Accuracy = 0.7602674307545367\n",
      "Loss = 0.4694599869332788\n",
      "Val accuracy = 0.5816618911174785\n",
      "Val loss = 2.2432505921319237\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 92\n",
      "Accuracy = 0.7628143903215536\n",
      "Loss = 0.4658992549019114\n",
      "Val accuracy = 0.582378223495702\n",
      "Val loss = 2.242943816966476\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 93\n",
      "Accuracy = 0.7652817574021012\n",
      "Loss = 0.46243866684681195\n",
      "Val accuracy = 0.583810888252149\n",
      "Val loss = 2.2426570170450706\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 94\n",
      "Accuracy = 0.7678287169691181\n",
      "Loss = 0.459073977697191\n",
      "Val accuracy = 0.586676217765043\n",
      "Val loss = 2.242390110819694\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 95\n",
      "Accuracy = 0.7701368990767271\n",
      "Loss = 0.4558010861003096\n",
      "Val accuracy = 0.58810888252149\n",
      "Val loss = 2.2421430259704693\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 96\n",
      "Accuracy = 0.7721267112384591\n",
      "Loss = 0.4526160259382048\n",
      "Val accuracy = 0.5888252148997135\n",
      "Val loss = 2.241915668682985\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 97\n",
      "Accuracy = 0.7742757083731295\n",
      "Loss = 0.44951502294747714\n",
      "Val accuracy = 0.5888252148997135\n",
      "Val loss = 2.241707902697326\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 98\n",
      "Accuracy = 0.7770614453995542\n",
      "Loss = 0.4464945091308144\n",
      "Val accuracy = 0.5916905444126075\n",
      "Val loss = 2.241519537621566\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 99\n",
      "Accuracy = 0.7794492199936326\n",
      "Loss = 0.4435510074720334\n",
      "Val accuracy = 0.5959885386819485\n",
      "Val loss = 2.241350330801066\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 100\n",
      "Accuracy = 0.7811206622094874\n",
      "Loss = 0.44068096724462935\n",
      "Val accuracy = 0.6010028653295129\n",
      "Val loss = 2.241200017310157\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 101\n",
      "Accuracy = 0.7831900668576887\n",
      "Loss = 0.437880766483476\n",
      "Val accuracy = 0.6017191977077364\n",
      "Val loss = 2.2410683707270684\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 102\n",
      "Accuracy = 0.7853390639923591\n",
      "Loss = 0.43514697442712036\n",
      "Val accuracy = 0.6024355300859598\n",
      "Val loss = 2.24095524989812\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 103\n",
      "Accuracy = 0.7866125437758675\n",
      "Loss = 0.43247652889026983\n",
      "Val accuracy = 0.6038681948424068\n",
      "Val loss = 2.2408605903451115\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 104\n",
      "Accuracy = 0.7901146131805158\n",
      "Loss = 0.4298663584123091\n",
      "Val accuracy = 0.6060171919770774\n",
      "Val loss = 2.24078438463205\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 105\n",
      "Accuracy = 0.7909901305316778\n",
      "Loss = 0.42731292506125335\n",
      "Val accuracy = 0.6067335243553008\n",
      "Val loss = 2.240726694457267\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 106\n",
      "Accuracy = 0.7924227952881248\n",
      "Loss = 0.42481254997797424\n",
      "Val accuracy = 0.6067335243553008\n",
      "Val loss = 2.2406876458867626\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 107\n",
      "Accuracy = 0.7943330149633875\n",
      "Loss = 0.42236212309505355\n",
      "Val accuracy = 0.6095988538681948\n",
      "Val loss = 2.2406673143717457\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 108\n",
      "Accuracy = 0.7964820120980579\n",
      "Loss = 0.4199595853835508\n",
      "Val accuracy = 0.6117478510028653\n",
      "Val loss = 2.2406655423824855\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 109\n",
      "Accuracy = 0.7983126392868514\n",
      "Loss = 0.4176039552799323\n",
      "Val accuracy = 0.6146131805157593\n",
      "Val loss = 2.2406818814493104\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 110\n",
      "Accuracy = 0.7995065265838904\n",
      "Loss = 0.415294063089364\n",
      "Val accuracy = 0.6181948424068768\n",
      "Val loss = 2.240715668555422\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 111\n",
      "Accuracy = 0.8011779687997453\n",
      "Loss = 0.41302739927231175\n",
      "Val accuracy = 0.6189111747851003\n",
      "Val loss = 2.2407663268000073\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 112\n",
      "Accuracy = 0.8028494110156001\n",
      "Loss = 0.41080148060611044\n",
      "Val accuracy = 0.6203438395415473\n",
      "Val loss = 2.2408335395073586\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 113\n",
      "Accuracy = 0.8046800382043935\n",
      "Loss = 0.4086153246485124\n",
      "Val accuracy = 0.6210601719197708\n",
      "Val loss = 2.240917154170144\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 114\n",
      "Accuracy = 0.8072269977714104\n",
      "Loss = 0.406469102798674\n",
      "Val accuracy = 0.6232091690544412\n",
      "Val loss = 2.2410171336870843\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 115\n",
      "Accuracy = 0.8087392550143266\n",
      "Loss = 0.40436299582016755\n",
      "Val accuracy = 0.6232091690544412\n",
      "Val loss = 2.2411335347150634\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 116\n",
      "Accuracy = 0.8106494746895893\n",
      "Loss = 0.40229646977734906\n",
      "Val accuracy = 0.6246418338108882\n",
      "Val loss = 2.2412664380535494\n",
      "Nombre d'itérations par époque = 196\n",
      "Epoch 117\n",
      "Accuracy = 0.8127984718242598\n",
      "Loss = 0.40026827344675375\n",
      "Val accuracy = 0.6267908309455588\n",
      "Val loss = 2.2414158791121888\n",
      "Nombre d'itérations par époque = 196\n"
     ]
    }
   ],
   "source": [
    "net.Adam(X_train, y_train, 0.1, 1000, 64, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.write_output(X_to_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d14695ea5945e3f4f0ac238f520c0cbdd58c9ea49b8d1a8480368eb73727c69d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
