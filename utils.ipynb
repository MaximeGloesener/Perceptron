{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.utils import shuffle\n",
    "import csv \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lecture des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat(\"data_doc.mat\")\n",
    "X = mat['Xts'].T.toarray()\n",
    "df_y = pd.DataFrame(mat['yts'])\n",
    "y = pd.get_dummies(df_y[0]).to_numpy() # OneHotEncoding\n",
    "X_to_predict = mat['Xvr'].T.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation entre 0 et 1 \n",
    "X = normalize(X)\n",
    "X_to_predict = normalize(X_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scaler = StandardScaler()\\nX = scaler.fit_transform(X)\\nX_to_predict = scaler.transform(X_to_predict)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalisation autour de 0 moyenne nulle et même variance\n",
    "\"\"\"scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_to_predict = scaler.transform(X_to_predict)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data en entrainement et validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self, mots, classe, method=None):\n",
    "        \"\"\"Initialisation des poids et des biais \"\"\"\n",
    "        if method is None:\n",
    "            # init uniform\n",
    "            self.weights = np.random.randn(mots, classe)\n",
    "            self.biases = np.random.randn(classe)\n",
    "        elif method == \"xavier\":\n",
    "            F_in = mots\n",
    "            F_out = classe \n",
    "            limit = np.sqrt(6 / float(F_in + F_out))\n",
    "            self.weights = np.random.uniform(low=-limit, high=limit, size=(F_in, F_out))\n",
    "            self.biases = np.random.randn(classe)\n",
    "            \n",
    "       \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass pour calculer la sortie du réseau\"\"\"\n",
    "        # sortie z = W^t*X+B\n",
    "        z = np.dot(self.weights.T, x) + self.biases\n",
    "        # fct d'activation = sigmoïde\n",
    "        activation = sigmoid(z)\n",
    "        return z, activation\n",
    "\n",
    "\n",
    "    def evaluate_gradient(self, x, y):\n",
    "        \"\"\"Calcul des dérivées partielles de la loss pour un itéré x\"\"\"\n",
    "        # on récupère la valeur de z et act(z) \n",
    "        z, activation = self.forward(x)\n",
    "        # calculer les dérivées partielles pour la couche de sortie par rapport à W et B\n",
    "        delta_b = (activation-y)*sigmoid_prime(z)\n",
    "        delta_w = np.outer(x, delta_b)\n",
    "        return delta_b, delta_w\n",
    "\n",
    "\n",
    "    \n",
    "    def compute_gradient(self, X, y, lr):\n",
    "        \"\"\"Calcul le gradient pour un batch\"\"\"\n",
    "        \n",
    "        # stocker la somme des gradients des x du batch\n",
    "        somme_delta_b = np.zeros(self.biases.shape)\n",
    "        somme_delta_w = np.zeros(self.weights.shape)\n",
    "\n",
    "        for x,y in zip(X,y):\n",
    "            delta_b, delta_w = self.evaluate_gradient(x, y)\n",
    "            somme_delta_b+=delta_b\n",
    "            somme_delta_w+=delta_w\n",
    "        \n",
    "        return somme_delta_b, somme_delta_w\n",
    "\n",
    "\n",
    "                                                                                                                                  \n",
    "    def SGD(self, X, y, lr, epochs):\n",
    "        \"\"\"SGD batchsize=1\"\"\"\n",
    "        # shuffle les données\n",
    "        X, y = shuffle(X,y)\n",
    "        for epoch in range(epochs):\n",
    "            # à chaque époque on parcourt tous les X, on calcule le gradient et on met à jour les poids et le biais pour chaque X\n",
    "            for i in range(len(X)):\n",
    "                somme_delta_b, somme_delta_w =  self.compute_gradient(X[i], y[i], lr)\n",
    "                # update les poids      \n",
    "                self.weights -= (lr/X[i].shape[0])*somme_delta_w \n",
    "                self.biases -= (lr/X[i].shape[0])*somme_delta_b\n",
    "\n",
    "            # calcul de l'accuracy et de la loss pour cette époque \n",
    "            accuracy, loss = self.evaluate_model(X, y)\n",
    "            print(f'Epoch {epoch}')\n",
    "            print(f'Accuracy = {accuracy}')\n",
    "            print(f'Loss = {loss}')\n",
    "\n",
    "    def GD(self, X, y, lr, epochs):\n",
    "        \"\"\"Gradient descent\"\"\"\n",
    "        X, y = shuffle(X,y)\n",
    "        for epoch in range(epochs):\n",
    "            # à chaque époque, on met le gradient une seule fosi à jour\n",
    "            somme_delta_b, somme_delta_w =  self.compute_gradient(X, y, lr)\n",
    "            # update les poids      \n",
    "            self.weights -= (lr/X.shape[0])*somme_delta_w \n",
    "            self.biases -= (lr/X.shape[0])*somme_delta_b\n",
    "\n",
    "            # calcul de l'accuracy et de la loss pour cette époque \n",
    "            accuracy, loss = self.evaluate_model(X, y)\n",
    "            print(f'Epoch {epoch}')\n",
    "            print(f'Accuracy = {accuracy}')\n",
    "            print(f'Loss = {loss}')\n",
    "\n",
    "    \n",
    "    def SGD_batch(self, X, y, lr, epochs, batch_size):\n",
    "        \"\"\"SGD+mini-batch\"\"\"\n",
    "        # shuffle les données\n",
    "        X, y = shuffle(X,y)\n",
    "        losses = [10**8]\n",
    "        for epoch in range(epochs):\n",
    "            # à chaque époque, on met à jour W et B avec mini-batchs\n",
    "            num_samples = y.shape[0]\n",
    "            ret = num_samples % batch_size\n",
    "            # si taille des données pas divisable par batch size alors resize les données\n",
    "            if ret != 0:\n",
    "                X_resize = X[:len(X)-ret]\n",
    "                y_resize = y[:len(y)-ret]\n",
    "\n",
    "            iterations = int(num_samples / batch_size)\n",
    "            print(f\"Nombre d'itérations par époque = {iterations}\")\n",
    "            for i in range(iterations):\n",
    "                # pour chaque mini-batch on veut entrainer le modèle et mettre à jour les poids\n",
    "                start = i * batch_size\n",
    "                end = start+batch_size\n",
    "                X_batch = X_resize[start:end, :]\n",
    "                y_batch = y_resize[start:end, :]\n",
    "                somme_delta_b, somme_delta_w =  self.compute_gradient(X_batch, y_batch, lr)\n",
    "                # update les poids      \n",
    "                self.weights -= (lr/X_batch.shape[0])*somme_delta_w \n",
    "                self.biases -= (lr/X_batch.shape[0])*somme_delta_b\n",
    "\n",
    "            # calcul de l'accuracy et de la loss pour cette époque \n",
    "            accuracy, loss = self.evaluate_model(X, y)\n",
    "            print(f'Epoch {epoch}')\n",
    "            print(f'Accuracy = {accuracy}')\n",
    "            print(f'Loss = {loss}')\n",
    "\n",
    "            # update le learning rate si on a une meilleure loss alors lr/2\n",
    "            if loss>losses[-1]:\n",
    "                lr/=2\n",
    "            losses.append(loss)\n",
    "\n",
    "    def Adam(self, X, y, lr, epochs, batch_size, X_val, y_val):\n",
    "        # init les paramètres pour Adam\n",
    "        beta_1 = 0.9\n",
    "        beta_2 = 0.999\t\t\t\t\t\n",
    "        epsilon = 1e-8\n",
    "        # init le vecteur\n",
    "        t = 1\t\t\t\t\t\t\n",
    "        m_dw = m_db = v_dw = v_db = 0 \n",
    "        X, y = shuffle(X,y)\n",
    "        losses = [10**8]\n",
    "        val_losses = [10**8]\n",
    "        # flag utilisé pour early stopping si val loss >>>\n",
    "        flag = 0    \n",
    "        for epoch in range(epochs):\n",
    "            # à chaque époque, on met à jour W et B avec mini-batchs\n",
    "            num_samples = y.shape[0]\n",
    "            ret = num_samples % batch_size\n",
    "            # si taille des données pas divisable par batch size alors resize les données\n",
    "            if ret != 0:\n",
    "                X_resize = X[:len(X)-ret]\n",
    "                y_resize = y[:len(y)-ret]\n",
    "\n",
    "            iterations = int(num_samples / batch_size)\n",
    "            print(f\"Nombre d'itérations par époque = {iterations}\")\n",
    "            for i in range(iterations):\n",
    "                # pour chaque mini-batch on veut entrainer le modèle et mettre à jour les poids\n",
    "                start = i * batch_size\n",
    "                end = start+batch_size\n",
    "                X_batch = X_resize[start:end, :]\n",
    "                y_batch = y_resize[start:end, :]\n",
    "                grad_b, grad_w =  self.compute_gradient(X_batch, y_batch, lr)\n",
    "                # adam update\n",
    "                # momentum poids\n",
    "                m_dw = beta_1*m_dw + (1-beta_1)*grad_w\n",
    "                # momentum biais\n",
    "                m_db = beta_1*m_db + (1-beta_1)*grad_b\n",
    "\n",
    "                # poids\n",
    "                v_dw = beta_2*v_dw + (1-beta_2)*(grad_w**2)\n",
    "                # biais\n",
    "                v_db = beta_2*v_db + (1-beta_2)*(grad_b**2)\n",
    "\n",
    "                # correction\n",
    "                m_dw_corr = m_dw/(1-beta_1**t)\n",
    "                m_db_corr = m_db/(1-beta_1**t)\n",
    "                v_dw_corr = v_dw/(1-beta_2**t)\n",
    "                v_db_corr = v_db/(1-beta_2**t)\n",
    "                # update les poids      \n",
    "                self.weights -= (lr/X.shape[0])*(m_dw_corr/(np.sqrt(v_dw_corr)+epsilon))\n",
    "                self.biases -= (lr/X.shape[0])*(m_db_corr/(np.sqrt(v_db_corr)+epsilon))\n",
    "\n",
    "            # calcul de l'accuracy et de la loss pour cette époque \n",
    "            accuracy, loss = self.evaluate_model(X, y)\n",
    "            print(f'Epoch {epoch}')\n",
    "            print(f'Accuracy = {accuracy}')\n",
    "            print(f'Loss = {loss}')\n",
    "            if loss > losses[-1]:\n",
    "                lr /= 2\n",
    "            losses.append(loss)\n",
    "\n",
    "            val_accuracy, val_loss = self.evaluate_model(X_val, y_val)\n",
    "            print(f'Val accuracy = {val_accuracy}')\n",
    "            print(f'Val loss = {val_loss}')\n",
    "            if val_loss > val_losses[-1]:\n",
    "                flag+=1\n",
    "            else:\n",
    "                flag=0\n",
    "            if flag>10:\n",
    "                print('EARLY STOPPING')\n",
    "                exit()\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Prediction sur des nouvelles données\"\"\"\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            z, act = self.forward(x)\n",
    "            preds.append(act)\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def evaluate_model(self, X, Y):\n",
    "        \"\"\"Calcule l'accuracy du modèle\n",
    "        X = vecteur qui contient des X d'entrées\n",
    "        Y = vecteur de vraie valeurs\n",
    "        \"\"\"\n",
    "        preds = self.predict(X)\n",
    "        loss = (1/(2*Y.shape[0])) * np.linalg.norm(preds - Y, 'fro') ** 2\n",
    "        predicted = np.array([pred.argmax() for pred in preds])\n",
    "        true_y = np.array([y.argmax() for y in Y])\n",
    "        # si predicted == la vraie valeur (test_y) alors True sinon False \n",
    "        correct = predicted == true_y\n",
    "        accuracy = (correct.sum() / len(correct))\n",
    "        return accuracy, loss\n",
    "\n",
    "    def write_output(self, X):\n",
    "        preds = self.predict(X)\n",
    "        predicted = np.array([np.argmax(pred) for pred in preds])\n",
    "        with open('output.csv' ,'w', newline='') as fout:\n",
    "            writer = csv.writer(fout)\n",
    "            writer.writerow([\"id\", \"class\"])\n",
    "            for i,pred in enumerate(predicted, start=1):\n",
    "                writer.writerow([i, (pred+1)*100+1])\n",
    "\n",
    "        \n",
    "def sigmoid(z):\n",
    "    \"\"\"Fonction d'activation sigmoïde\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Dérivée de la sigmoïde\"\"\"\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(X.shape[1], y.shape[1], 'xavier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'itérations par époque = 174\n",
      "Epoch 0\n",
      "Accuracy = 0.05050143266475645\n",
      "Loss = 1.6995082048329633\n",
      "Val accuracy = 0.04835243553008596\n",
      "Val loss = 1.7102434970166251\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 1\n",
      "Accuracy = 0.054709885386819486\n",
      "Loss = 1.2624533494255732\n",
      "Val accuracy = 0.050143266475644696\n",
      "Val loss = 1.2761090965331154\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 2\n",
      "Accuracy = 0.07924426934097421\n",
      "Loss = 1.026358196490578\n",
      "Val accuracy = 0.06984240687679083\n",
      "Val loss = 1.0414354013409557\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 3\n",
      "Accuracy = 0.12714899713467048\n",
      "Loss = 0.8786594980935355\n",
      "Val accuracy = 0.10315186246418338\n",
      "Val loss = 0.8947328291090855\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 4\n",
      "Accuracy = 0.19108166189111747\n",
      "Loss = 0.7777399010817182\n",
      "Val accuracy = 0.15436962750716332\n",
      "Val loss = 0.7946815238348418\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 5\n",
      "Accuracy = 0.25304441260744986\n",
      "Loss = 0.704377266175653\n",
      "Val accuracy = 0.2080945558739255\n",
      "Val loss = 0.7221635744956142\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 6\n",
      "Accuracy = 0.31787249283667623\n",
      "Loss = 0.6485023652593268\n",
      "Val accuracy = 0.26468481375358166\n",
      "Val loss = 0.6671508627703264\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 7\n",
      "Accuracy = 0.3818051575931232\n",
      "Loss = 0.6043586694205672\n",
      "Val accuracy = 0.3108882521489971\n",
      "Val loss = 0.6239035755234733\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 8\n",
      "Accuracy = 0.44000716332378226\n",
      "Loss = 0.5684324949861892\n",
      "Val accuracy = 0.35888252148997135\n",
      "Val loss = 0.5889138445839883\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 9\n",
      "Accuracy = 0.5036712034383954\n",
      "Loss = 0.5384668473938007\n",
      "Val accuracy = 0.41045845272206305\n",
      "Val loss = 0.5599249202069395\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 10\n",
      "Accuracy = 0.5564111747851003\n",
      "Loss = 0.5129513375751478\n",
      "Val accuracy = 0.4684813753581662\n",
      "Val loss = 0.5354235529626779\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 11\n",
      "Accuracy = 0.602256446991404\n",
      "Loss = 0.4908405762983452\n",
      "Val accuracy = 0.5150429799426934\n",
      "Val loss = 0.5143597569344536\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 12\n",
      "Accuracy = 0.6437141833810889\n",
      "Loss = 0.4713902824090242\n",
      "Val accuracy = 0.5540830945558739\n",
      "Val loss = 0.49598378017155226\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 13\n",
      "Accuracy = 0.6798889684813754\n",
      "Loss = 0.4540576503214632\n",
      "Val accuracy = 0.5870343839541547\n",
      "Val loss = 0.4797470367039094\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 14\n",
      "Accuracy = 0.7107808022922636\n",
      "Loss = 0.4384384980092359\n",
      "Val accuracy = 0.6153295128939829\n",
      "Val loss = 0.4652396236051878\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 15\n",
      "Accuracy = 0.7354942693409742\n",
      "Loss = 0.42422631591194243\n",
      "Val accuracy = 0.6429083094555874\n",
      "Val loss = 0.45214961365819845\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 16\n",
      "Accuracy = 0.7576110315186246\n",
      "Loss = 0.4111848152179205\n",
      "Val accuracy = 0.660458452722063\n",
      "Val loss = 0.4402357695410109\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 17\n",
      "Accuracy = 0.7757879656160458\n",
      "Loss = 0.39912906785515084\n",
      "Val accuracy = 0.6758595988538681\n",
      "Val loss = 0.4293087971664769\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 18\n",
      "Accuracy = 0.7920845272206304\n",
      "Loss = 0.3879122843885341\n",
      "Val accuracy = 0.6916189111747851\n",
      "Val loss = 0.4192181930836892\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 19\n",
      "Accuracy = 0.8064111747851003\n",
      "Loss = 0.37741639747274075\n",
      "Val accuracy = 0.705945558739255\n",
      "Val loss = 0.4098428545518774\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 20\n",
      "Accuracy = 0.8189469914040115\n",
      "Loss = 0.3675452757163266\n",
      "Val accuracy = 0.7159742120343839\n",
      "Val loss = 0.40108427815021436\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 21\n",
      "Accuracy = 0.8296919770773639\n",
      "Loss = 0.3582197872131987\n",
      "Val accuracy = 0.7231375358166189\n",
      "Val loss = 0.3928615712062083\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 22\n",
      "Accuracy = 0.8360494269340975\n",
      "Loss = 0.3493741768946594\n",
      "Val accuracy = 0.7310171919770774\n",
      "Val loss = 0.38510774937716014\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 23\n",
      "Accuracy = 0.8427650429799427\n",
      "Loss = 0.3409533808259091\n",
      "Val accuracy = 0.7392550143266475\n",
      "Val loss = 0.3777669548632376\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 24\n",
      "Accuracy = 0.8497492836676218\n",
      "Loss = 0.3329110085839571\n",
      "Val accuracy = 0.7474928366762178\n",
      "Val loss = 0.3707923376155035\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 25\n",
      "Accuracy = 0.8549426934097422\n",
      "Loss = 0.32520780102444113\n",
      "Val accuracy = 0.751432664756447\n",
      "Val loss = 0.36414441630130634\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 26\n",
      "Accuracy = 0.8595093123209169\n",
      "Loss = 0.3178104259115784\n",
      "Val accuracy = 0.7546561604584527\n",
      "Val loss = 0.3577897883649968\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 27\n",
      "Accuracy = 0.8653295128939829\n",
      "Loss = 0.3106905146069524\n",
      "Val accuracy = 0.7607449856733525\n",
      "Val loss = 0.351700096435111\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 28\n",
      "Accuracy = 0.8703438395415473\n",
      "Loss = 0.3038238733825837\n",
      "Val accuracy = 0.7657593123209169\n",
      "Val loss = 0.34585118604593845\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 29\n",
      "Accuracy = 0.8749104584527221\n",
      "Loss = 0.297189825406994\n",
      "Val accuracy = 0.7696991404011462\n",
      "Val loss = 0.34022240989151464\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 30\n",
      "Accuracy = 0.8789398280802292\n",
      "Loss = 0.29077065547989656\n",
      "Val accuracy = 0.7725644699140402\n",
      "Val loss = 0.33479604826562603\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 31\n",
      "Accuracy = 0.8823424068767909\n",
      "Loss = 0.2845511401291659\n",
      "Val accuracy = 0.7775787965616046\n",
      "Val loss = 0.3295568250759372\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 32\n",
      "Accuracy = 0.8857449856733525\n",
      "Loss = 0.2785181516956142\n",
      "Val accuracy = 0.7811604584527221\n",
      "Val loss = 0.32449150481714856\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 33\n",
      "Accuracy = 0.8889684813753582\n",
      "Loss = 0.2726603276777663\n",
      "Val accuracy = 0.7861747851002865\n",
      "Val loss = 0.3195885591359178\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 34\n",
      "Accuracy = 0.8924606017191977\n",
      "Loss = 0.2669677971816071\n",
      "Val accuracy = 0.7922636103151862\n",
      "Val loss = 0.314837893114311\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 35\n",
      "Accuracy = 0.8940723495702005\n",
      "Loss = 0.2614319560225228\n",
      "Val accuracy = 0.7972779369627507\n",
      "Val loss = 0.31023062202280294\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 36\n",
      "Accuracy = 0.896310888252149\n",
      "Loss = 0.2560452817633903\n",
      "Val accuracy = 0.8005014326647565\n",
      "Val loss = 0.3057588897102231\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 37\n",
      "Accuracy = 0.8994448424068768\n",
      "Loss = 0.25080118024924464\n",
      "Val accuracy = 0.8033667621776505\n",
      "Val loss = 0.30141572039970405\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 38\n",
      "Accuracy = 0.9026683381088825\n",
      "Loss = 0.24569385614191055\n",
      "Val accuracy = 0.8076647564469914\n",
      "Val loss = 0.2971948965921016\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 39\n",
      "Accuracy = 0.9055336676217765\n",
      "Loss = 0.24071820141800546\n",
      "Val accuracy = 0.8105300859598854\n",
      "Val loss = 0.29309085700280774\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 40\n",
      "Accuracy = 0.9085780802292264\n",
      "Loss = 0.23586969747617706\n",
      "Val accuracy = 0.8116045845272206\n",
      "Val loss = 0.2890986098290006\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 41\n",
      "Accuracy = 0.9110852435530086\n",
      "Loss = 0.2311443280864705\n",
      "Val accuracy = 0.8133954154727794\n",
      "Val loss = 0.2852136579813977\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 42\n",
      "Accuracy = 0.9127865329512894\n",
      "Loss = 0.22653850165788053\n",
      "Val accuracy = 0.8151862464183381\n",
      "Val loss = 0.2814319340550658\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 43\n",
      "Accuracy = 0.9155623209169055\n",
      "Loss = 0.2220489820736799\n",
      "Val accuracy = 0.8166189111747851\n",
      "Val loss = 0.2777497436487778\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 44\n",
      "Accuracy = 0.917621776504298\n",
      "Loss = 0.21767282765643994\n",
      "Val accuracy = 0.8198424068767909\n",
      "Val loss = 0.2741637161363742\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 45\n",
      "Accuracy = 0.9193230659025788\n",
      "Loss = 0.21340733779310211\n",
      "Val accuracy = 0.8212750716332379\n",
      "Val loss = 0.2706707621860152\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 46\n",
      "Accuracy = 0.9205766475644699\n",
      "Loss = 0.20925000654685508\n",
      "Val accuracy = 0.8237822349570201\n",
      "Val loss = 0.267268037301664\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 47\n",
      "Accuracy = 0.9229942693409742\n",
      "Loss = 0.20519848236582242\n",
      "Val accuracy = 0.8255730659025788\n",
      "Val loss = 0.2639529105252285\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 48\n",
      "Accuracy = 0.9255909742120344\n",
      "Loss = 0.2012505328865776\n",
      "Val accuracy = 0.8255730659025788\n",
      "Val loss = 0.2607229373079364\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 49\n",
      "Accuracy = 0.927560888252149\n",
      "Loss = 0.19740401391981988\n",
      "Val accuracy = 0.8273638968481375\n",
      "Val loss = 0.25757583556107294\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 50\n",
      "Accuracy = 0.9293517191977078\n",
      "Loss = 0.19365684198868938\n",
      "Val accuracy = 0.8291547277936963\n",
      "Val loss = 0.25450946402080254\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 51\n",
      "Accuracy = 0.9311425501432665\n",
      "Loss = 0.19000697013080523\n",
      "Val accuracy = 0.8298710601719198\n",
      "Val loss = 0.2515218022477518\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 52\n",
      "Accuracy = 0.9323961318051576\n",
      "Loss = 0.1864523669763005\n",
      "Val accuracy = 0.832378223495702\n",
      "Val loss = 0.24861093184433206\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 53\n",
      "Accuracy = 0.9333810888252149\n",
      "Loss = 0.18299099932619428\n",
      "Val accuracy = 0.8341690544412608\n",
      "Val loss = 0.24577501877586283\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 54\n",
      "Accuracy = 0.9344555873925502\n",
      "Loss = 0.17962081853347586\n",
      "Val accuracy = 0.8348853868194842\n",
      "Val loss = 0.24301229694379944\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 55\n",
      "Accuracy = 0.936067335243553\n",
      "Loss = 0.17633975092378368\n",
      "Val accuracy = 0.8363180515759312\n",
      "Val loss = 0.24032105332567316\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 56\n",
      "Accuracy = 0.9374104584527221\n",
      "Loss = 0.17314569231581148\n",
      "Val accuracy = 0.8377507163323782\n",
      "Val loss = 0.2376996150469992\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 57\n",
      "Accuracy = 0.9383058739255015\n",
      "Loss = 0.17003650646914525\n",
      "Val accuracy = 0.839541547277937\n",
      "Val loss = 0.2351463386945586\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 58\n",
      "Accuracy = 0.9398280802292264\n",
      "Loss = 0.16701002705727444\n",
      "Val accuracy = 0.8409742120343839\n",
      "Val loss = 0.23265960204852856\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 59\n",
      "Accuracy = 0.9407234957020058\n",
      "Loss = 0.1640640625802647\n",
      "Val accuracy = 0.8416905444126075\n",
      "Val loss = 0.2302377982444277\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 60\n",
      "Accuracy = 0.9418875358166189\n",
      "Loss = 0.16119640351924272\n",
      "Val accuracy = 0.8424068767908309\n",
      "Val loss = 0.22787933221506632\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 61\n",
      "Accuracy = 0.9426038681948424\n",
      "Loss = 0.15840483099948308\n",
      "Val accuracy = 0.8445558739255015\n",
      "Val loss = 0.22558261913562083\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 62\n",
      "Accuracy = 0.9435888252148997\n",
      "Loss = 0.155687126261905\n",
      "Val accuracy = 0.8452722063037249\n",
      "Val loss = 0.22334608451361468\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 63\n",
      "Accuracy = 0.9443946991404012\n",
      "Loss = 0.15304108032627475\n",
      "Val accuracy = 0.8467048710601719\n",
      "Val loss = 0.2211681655301423\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 64\n",
      "Accuracy = 0.9456482808022922\n",
      "Loss = 0.15046450334270522\n",
      "Val accuracy = 0.8492120343839542\n",
      "Val loss = 0.21904731324301593\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 65\n",
      "Accuracy = 0.9468123209169055\n",
      "Loss = 0.14795523325236795\n",
      "Val accuracy = 0.8492120343839542\n",
      "Val loss = 0.21698199529754092\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 66\n",
      "Accuracy = 0.9475286532951289\n",
      "Loss = 0.14551114349922029\n",
      "Val accuracy = 0.8502865329512894\n",
      "Val loss = 0.21497069884574455\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 67\n",
      "Accuracy = 0.9481554441260746\n",
      "Loss = 0.1431301496426254\n",
      "Val accuracy = 0.8527936962750716\n",
      "Val loss = 0.21301193343941002\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 68\n",
      "Accuracy = 0.948871776504298\n",
      "Loss = 0.14081021481137684\n",
      "Val accuracy = 0.8535100286532952\n",
      "Val loss = 0.21110423372709064\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 69\n",
      "Accuracy = 0.9494985673352435\n",
      "Loss = 0.1385493540111585\n",
      "Val accuracy = 0.8535100286532952\n",
      "Val loss = 0.2092461618441054\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 70\n",
      "Accuracy = 0.9502148997134671\n",
      "Loss = 0.13634563734970248\n",
      "Val accuracy = 0.8542263610315186\n",
      "Val loss = 0.2074363094338272\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 71\n",
      "Accuracy = 0.9510207736389685\n",
      "Loss = 0.1341971922782465\n",
      "Val accuracy = 0.8545845272206304\n",
      "Val loss = 0.205673299277132\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 72\n",
      "Accuracy = 0.951737106017192\n",
      "Loss = 0.13210220496736497\n",
      "Val accuracy = 0.8545845272206304\n",
      "Val loss = 0.20395578653515212\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 73\n",
      "Accuracy = 0.9522743553008596\n",
      "Loss = 0.13005892094328453\n",
      "Val accuracy = 0.8556590257879656\n",
      "Val loss = 0.20228245962999342\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 74\n",
      "Accuracy = 0.9533488538681948\n",
      "Loss = 0.12806564511029445\n",
      "Val accuracy = 0.8567335243553008\n",
      "Val loss = 0.20065204080056714\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 75\n",
      "Accuracy = 0.9538861031518625\n",
      "Loss = 0.12612074127817127\n",
      "Val accuracy = 0.8567335243553008\n",
      "Val loss = 0.1990632863775238\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 76\n",
      "Accuracy = 0.9547815186246418\n",
      "Loss = 0.12422263130270055\n",
      "Val accuracy = 0.8567335243553008\n",
      "Val loss = 0.19751498682350888\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 77\n",
      "Accuracy = 0.9554083094555874\n",
      "Loss = 0.1223697939341576\n",
      "Val accuracy = 0.8574498567335244\n",
      "Val loss = 0.19600596658361055\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 78\n",
      "Accuracy = 0.9558560171919771\n",
      "Loss = 0.12056076345441565\n",
      "Val accuracy = 0.8574498567335244\n",
      "Val loss = 0.19453508378694628\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 79\n",
      "Accuracy = 0.9561246418338109\n",
      "Loss = 0.11879412816921125\n",
      "Val accuracy = 0.8581661891117478\n",
      "Val loss = 0.19310122983480565\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 80\n",
      "Accuracy = 0.9564828080229226\n",
      "Loss = 0.11706852880870286\n",
      "Val accuracy = 0.8603151862464183\n",
      "Val loss = 0.1917033289044971\n",
      "Nombre d'itérations par époque = 174\n",
      "Epoch 81\n",
      "Accuracy = 0.9571991404011462\n",
      "Loss = 0.11538265687726025\n",
      "Val accuracy = 0.8606733524355301\n",
      "Val loss = 0.1903403373917596\n",
      "Nombre d'itérations par époque = 174\n"
     ]
    }
   ],
   "source": [
    "net.Adam(X_train,y_train, 10, 1000, 64, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.write_output(X_to_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28c92afe8325fc0816b2f334f44f38e4b06e562e4c3a673584693ef65fd7d28f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
